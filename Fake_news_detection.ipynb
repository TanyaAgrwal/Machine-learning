{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake news detection",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBqi10I31lgtoV+2ErOdhK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanyaAgrwal/Machine-learning/blob/main/Fake_news_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GxWUnOl1exT"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIVNURgr4HDQ"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iba7prJ28CXr"
      },
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Fake news dataset/train.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLLh9uuJ8XsU"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJpC2mMO8aF5"
      },
      "source": [
        "class_divisions=df.value_counts(df['label'])\r\n",
        "class_divisions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq2EqH358aHo"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4wlu70t9RFp"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aSTnOWH8aKu"
      },
      "source": [
        "title=df['title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqZUsGMa8aNv"
      },
      "source": [
        "title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqth__i79shl"
      },
      "source": [
        "import re\r\n",
        "from nltk.corpus import stopwords\r\n",
        "#from nltk.stem import PorterStemmer\r\n",
        "#ps=PorterStemmer()\r\n",
        "title_data=[]\r\n",
        "for i in range(len(title)):\r\n",
        "  text=re.sub(r'[^A-Za-z0-9%$]',' ',str(title[i]))\r\n",
        "  text=text.strip()\r\n",
        "  text=text.split()\r\n",
        "  text=[i for i in text if not i in stopwords.words('english')]\r\n",
        "  text=' '.join(text)\r\n",
        "  title_data.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLbbo0bS5SUo"
      },
      "source": [
        "#practice\r\n",
        "text1='my name is Tanya Agrawal, I got 90% in maths and @ ! is good in P.T. and i got $100000'\r\n",
        "text1=re.sub(r'[^A-Za-z0-9%$]',' ',text1)\r\n",
        "text1=text1.split()\r\n",
        "text1=' '.join(text1)\r\n",
        "text1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYvvF5SB-wR"
      },
      "source": [
        "title_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ4nrlyjiczo"
      },
      "source": [
        "#from sklearn.model_selection import train_test_split\r\n",
        "#X_train,X_test,y_train,y_test=train_test_split(title_data, df['label'].values, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze4_xB9C6m-1"
      },
      "source": [
        "df2=pd.read_csv('/content/drive/MyDrive/Fake news dataset/test.csv')\r\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFeYbuj07h9U"
      },
      "source": [
        "title2=df2['title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTHz7BfQ7rf5"
      },
      "source": [
        "title2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "107hk5GJ7Zn6"
      },
      "source": [
        "import re\r\n",
        "from nltk.corpus import stopwords\r\n",
        "#from nltk.stem import PorterStemmer\r\n",
        "#ps=PorterStemmer()\r\n",
        "title_data2=[]\r\n",
        "for i in range(len(title2)):\r\n",
        "  text2=re.sub(r'[^A-Za-z0-9%$]',' ',str(title2[i]))\r\n",
        "  text2=text2.strip()\r\n",
        "  text2=text2.split()\r\n",
        "  text2=[i for i in text2 if not i in stopwords.words('english')]\r\n",
        "  text2=' '.join(text2)\r\n",
        "  title_data2.append(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEWyYF8Z8B7V"
      },
      "source": [
        "title_data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMQKlQt5Gp7S"
      },
      "source": [
        "from google.colab import files\r\n",
        "\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "for fn in uploaded.keys():\r\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\r\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NRVeVjBGwK7"
      },
      "source": [
        "sub=pd.read_csv('/content/submit.csv')\r\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "texfbuYc6yxp"
      },
      "source": [
        "x=title_data+title_data2\r\n",
        "a=df['label'].values\r\n",
        "b=sub['label'].values\r\n",
        "y=np.concatenate((a,b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xx3sJIXHacJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test=train_test_split(x,y, test_size=0.2, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB-_qoqhjHUo"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "max_vocab=21628\r\n",
        "tokenizer= Tokenizer(num_words=max_vocab)\r\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EefE-YKnjOLZ"
      },
      "source": [
        "wordindex=tokenizer.word_index\r\n",
        "len(wordindex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Ho4I4YjZY5"
      },
      "source": [
        "train_seq=tokenizer.texts_to_sequences(X_train)\r\n",
        "test_seq=tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeV8Cy3IjiFJ"
      },
      "source": [
        "pad_train=pad_sequences(train_seq)\r\n",
        "pad_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgDssQg1jkWs"
      },
      "source": [
        "pad_test=pad_sequences(test_seq, maxlen=54)\r\n",
        "pad_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E319YnetjqlZ"
      },
      "source": [
        "from keras import Sequential\r\n",
        "from keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Flatten, Dropout, BatchNormalization\r\n",
        "model=Sequential()\r\n",
        "model.add(Embedding(22862,128,input_length=54))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(LSTM(80, return_sequences=True))\r\n",
        "model.add(GlobalMaxPooling1D())\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2-YnbWWkD2L"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNH3HBsnkHtw"
      },
      "source": [
        "history=model.fit(pad_train, y_train,batch_size=100, epochs=2 ,validation_data=(pad_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0HD1tmdklSy"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpSE8dDTkqXM"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('accuracy')\r\n",
        "plt.legend(['train','test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.title('loss')\r\n",
        "plt.legend(['train','test'])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYYH2f31lAZu"
      },
      "source": [
        "model.evaluate(pad_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_rlxE7nlS3O"
      },
      "source": [
        "y_pred=model.predict_classes(pad_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx26i4YslGCj"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm=confusion_matrix(y_test,y_pred)\r\n",
        "a_s=accuracy_score(y_test,y_pred)\r\n",
        "print(cm)\r\n",
        "print(a_s)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}